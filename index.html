<html lang="en-US"><head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<title>Which one is better to Learn for Autonomous Driving ROS2 or Apollo</title>
<meta name="description" content=">Which one is better to Learn for Autonomous Driving ROS2 or Apollo">
<meta name="keywords" content="Robot,Autonomous Driving,Apollo">
</head>

<body>

<article class="markdown-body entry-content container-lg" itemprop="text"><p dir="auto">Which one is better to Learn for Autonomous Driving ROS2 or Apollo</p>
<p dir="auto">Hi, my advice is that you need to all all the fundamental robotics and autonomous Driving related subjects, but Apollo should be prioritized with the core Algorithm. ROS2 is just a framework with scheduling and data communication. The autonomous driving technologies of various companies are nothing more than these mainstream solutions~ Perception-related BEV perception: BEV is the cornerstone of the current mainstream mass production solution. The unified feature expression can directly output multi-task results, such as 3D detection, BEV segmentation, online high-precision maps, etc.;</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">OCC occupancy grid</h2><a id="user-content-occ-occupancy-grid" class="anchor" aria-label="Permalink: OCC occupancy grid" href="#occ-occupancy-grid"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">OCC directly models the occupancy information of the 3D world space, which can effectively handle targets with irregular shapes and unclear semantics (such as road garbage and stones), etc., which is essential for driving/parking;</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">Pure visual monocular 3D perception</h2><a id="user-content-pure-visual-monocular-3d-perception" class="anchor" aria-label="Permalink: Pure visual monocular 3D perception" href="#pure-visual-monocular-3d-perception"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Monocular focuses on cost-effectiveness and has been widely used in various L2/L3 mass production solutions. Monocular 2D/3D/BEV and OCC also have their own unique development trends;</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">3D&amp;4D millimeter wave</h2><a id="user-content-3d4d-millimeter-wave" class="anchor" aria-label="Permalink: 3D&amp;4D millimeter wave" href="#3d4d-millimeter-wave"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">millimeter wave radar, especially 4D Radar is conquering the L4 high ground. Its distance measurement, speed measurement, angle measurement capabilities and unique perception solutions have allowed Radar to go its own way; Point cloud 3D target detection: Point cloud 3D detection is the basis of LV fusion. It has a very rich technical direction and is more difficult. It is currently mainly used in L4 and true value systems;</p>
<div class="markdown-heading" dir="auto"><h2 class="heading-element" dir="auto">LV fusion</h2><a id="user-content-lv-fusion" class="anchor" aria-label="Permalink: LV fusion" href="#lv-fusion"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The purpose of fusion is to solve problems such as visual occlusion and single-frame instability. There is no doubt that LV fusion is the current mainstream mass production direction; RV fusion: The all-weather operation characteristics of millimeter waves make RV fusion complementary and improve perception performance as a whole;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Lane line detection &amp; online high-precision map</h3><a id="user-content-lane-line-detection--online-high-precision-map" class="anchor" aria-label="Permalink: Lane line detection &amp; online high-precision map" href="#lane-line-detection--online-high-precision-map"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Lane line detection as As the basic task of autonomous driving, it is gradually developing towards online high-precision maps. This task can be said to be the core of mapless NOA; Transformer: Since ViT swept CV, the SOTA models in autonomous driving have more or less had Transformer, which can be said to be leading the trend; Multi-sensor fusion target tracking: In order to facilitate downstream use, perception needs to obtain the timing information of the target, so as to "string" the obstacles together. Currently, both dynamic and static targets can use tracking to output stably. This technology stack involves single sensor/multi-sensor, Kalman filtering, etc.;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">2D target detection</h3><a id="user-content-2d-target-detection" class="anchor" aria-label="Permalink: 2D target detection" href="#2d-target-detection"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">2D target detection is very important in autonomous driving. It still occupies a place in driving, such as traffic light detection, road signs, etc.</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Prediction &amp; Regulation Trajectory prediction</h3><a id="user-content-prediction--regulation-trajectory-prediction" class="anchor" aria-label="Permalink: Prediction &amp; Regulation Trajectory prediction" href="#prediction--regulation-trajectory-prediction"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Trajectory prediction is an important module connecting perception and regulation. Compared with perception, this direction is smaller in scale, but has higher technical requirements. It is a niche but very popular field;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Planning and control</h3><a id="user-content-planning-and-control" class="anchor" aria-label="Permalink: Planning and control" href="#planning-and-control"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Regulation and control, as the most downstream module of the entire autonomous driving, directly determines the safety and comfort of autonomous driving. This field has high theoretical requirements and a higher upper limit;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">Autonomous driving tool chain TensorRT deployment</h3><a id="user-content-autonomous-driving-tool-chain-tensorrt-deployment" class="anchor" aria-label="Permalink: Autonomous driving tool chain TensorRT deployment" href="#autonomous-driving-tool-chain-tensorrt-deployment"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The model cannot be separated from the deployment and optimization of the actual vehicle. This field involves a lot of CUDA programming and TensorRT deployment, which can be said to be engineering The most demanding direction;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">simulation test</h3><a id="user-content-simulation-test" class="anchor" aria-label="Permalink: simulation test" href="#simulation-test"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">simulation as the core of the test link can open up the entire data closed loop, especially combined with the currently popular 3DGS three-dimensional reconstruction, it has great potential;</p>
<div class="markdown-heading" dir="auto"><h3 class="heading-element" dir="auto">C++ programming</h3><a id="user-content-c-programming" class="anchor" aria-label="Permalink: C++ programming" href="#c-programming"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">C++ is the most widely used and most important language in autonomous driving, a solid foundation for mass production and a tool that can never be avoided;</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">sensor calibration multi-sensor calibration</h4><a id="user-content-sensor-calibration-multi-sensor-calibration" class="anchor" aria-label="Permalink: sensor calibration multi-sensor calibration" href="#sensor-calibration-multi-sensor-calibration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">the accuracy of calibration parameters directly affects the application of downstream perception and positioning fusion. This technical direction involves sensors such as Lidar/Radar/Camera/IMU;</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">camera calibration</h4><a id="user-content-camera-calibration" class="anchor" aria-label="Permalink: camera calibration" href="#camera-calibration"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">camera calibration is the most widely used of all sensors. How to choose the imaging model? How to calibrate the internal and external parameters? How to calibrate binocular &amp; surround view &amp; fisheye? How to choose the calibration board is worth exploring;</p>
<div class="markdown-heading" dir="auto"><h5 class="heading-element" dir="auto">End-to-end autonomous driving at the forefront of autonomous driving</h5><a id="user-content-end-to-end-autonomous-driving-at-the-forefront-of-autonomous-driving" class="anchor" aria-label="Permalink: End-to-end autonomous driving at the forefront of autonomous driving" href="#end-to-end-autonomous-driving-at-the-forefront-of-autonomous-driving"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">End-to-end autonomous driving refers to the direct output of vehicle control signals based on input. Tesla has verified the feasibility of the solution, and China is catching up in strides. It will definitely be the high ground for intelligent driving competition in 2024;</p>
<div class="markdown-heading" dir="auto"><h5 class="heading-element" dir="auto">World model</h5><a id="user-content-world-model" class="anchor" aria-label="Permalink: World model" href="#world-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The world model aims to understand autonomous driving from a higher dimension, using a large number of real-life videos to generate future scenes, which can be used to generate simulation data on a large scale, especially Corner Case;</p>
<div class="markdown-heading" dir="auto"><h4 class="heading-element" dir="auto">NeRF and autonomous driving</h4><a id="user-content-nerf-and-autonomous-driving" class="anchor" aria-label="Permalink: NeRF and autonomous driving" href="#nerf-and-autonomous-driving"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Unlike traditional three-dimensional reconstruction methods, NeRF/3D GS is faster and has better performance. It can also be connected with the simulation link, which is a killer for future data closed loops; Large model and autonomous driving: The combination of large language models and autonomous driving is also a cutting-edge field at present, and autonomous driving may usher in the GPT moment;</p>
<p dir="auto">For more informtion, you can visit <a href="http://www.deepnlp.org/search/robot" rel="nofollow">Robotic Search Engine</a> to find latest research papers, <a href="http://www.deepnlp.org/store/ai-agent" rel="nofollow">AI Agent Marketplace</a> and <a href="http://www.deepnlp.org/search/agent" rel="nofollow">AI Agent Search Engine</a> to find AI Agents related topics reviews and latest product information.</p>



</article>

<div>

<h2 class="heading-element" dir="auto">Related Sources</h2>
<h4 class="heading-element" dir="auto">Equation</h4>
<p dir="auto"><a href="http://www.deepnlp.org/equation">DeepNLP Equation Database</a> <br>
<a href="http://www.deepnlp.org/equation/category/math">Math Equations</a> <br>
<a href="http://www.deepnlp.org/equation/category/physics">Physics Equations</a> <br>
<a href="http://www.deepnlp.org/equation/category/nlp">NLP Equations</a> <br>
<a href="http://www.deepnlp.org/equation/category/machine%20learning">Machine Learning Equations</a> <br></p>
<h4 class="heading-element" dir="auto">AI Agent Marketplace and Search</h4>
<p dir="auto"><a href="http://www.deepnlp.org/search/agent">AI Agent Marketplace and Search</a> <br>
<a href="http://www.deepnlp.org/search/robot">Robot Search</a> <br>
<a href="http://www.deepnlp.org/search/equation">Equation and Academic search</a> <br>
<a href="http://www.deepnlp.org/search">AI Robot Comprehensive Search</a> <br>
<a href="http://www.deepnlp.org/question">AI &amp; Robot Question</a> <br>
<a href="http://www.deepnlp.org/community">AI &amp; Robot Community</a> <br></p>
<h4 class="heading-element" dir="auto">AI Agent</h4>
<p dir="auto"><a href="http://www.deepnlp.org/store/ai-agent">AI Agent Reviews</a> <br>
<a href="http://www.deepnlp.org/store/pub?category=ai-agent">AI Agent Publisher</a> <br>
<a href="http://www.deepnlp.org/store/pub/pub-microsoft-ai-agent">Microsoft AI Agents Reviews</a> <br>
<a href="http://www.deepnlp.org/store/pub/pub-claude-ai-agent">Claude AI Agents Reviews</a> <br>
<a href="http://www.deepnlp.org/store/pub/pub-openai-ai-agent">OpenAI AI Agents Reviews</a> <br>
<a href="http://www.deepnlp.org/store/pub/pub-agentgpt">AgentGPT AI Agents Reviews</a> <br>
<a href="http://www.deepnlp.org/store/pub/pub-salesforce-ai-agent">Saleforce AI Agents Reviews</a> <br>
<a href="http://www.deepnlp.org/store/ai-agent/ai-agent-builder">AI Agent Builder Reviews</a> <br></p>

</div>

</body>

</html>
